#!/usr/bin/env python3
"""
ä»å·²reviewçš„repos_xxx.mdç”Ÿæˆå†™ä½œæŒ‡å¼•æ–‡æ¡£
"""
import sys
import json
import re
from pathlib import Path
from datetime import datetime, timedelta

REVIEW_SIGNATURE_KEY = 'weekly_bot_reviewed'

def calculate_week_description(start_date_str, end_date_str):
    """æ ¹æ®æ—¥æœŸè·¨åº¦è®¡ç®—å‘¨æ•°æè¿°"""
    try:
        start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
        end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
        days_diff = (end_date - start_date).days + 1  # +1 åŒ…å«èµ·å§‹æ—¥æœŸ
        
        if 7<= days_diff < 14:
            return "ä¸ºå•å‘¨å‘¨æŠ¥"
        elif days_diff < 21:
            return "ä¸ºåŒå‘¨å‘¨æŠ¥"
        elif days_diff < 28:
            return "ä¸ºä¸‰å‘¨å‘¨æŠ¥"
        else:
            return f"ä¸º{days_diff}å¤©å‘¨æŠ¥"
    except:
        return "ä¸ºå‘¨æŠ¥"

def update_previous_weekly_embed(current_weekly_num):
    """è‡ªåŠ¨æ›´æ–°ä¸Šä¸€å‘¨çš„embedæ ¼å¼ï¼ˆä»[+]æ”¹ä¸º[+-]ï¼‰"""
    if current_weekly_num <= 1:
        return  # ç¬¬ä¸€æœŸå‘¨æŠ¥æ²¡æœ‰ä¸Šä¸€æœŸ
    
    previous_num = current_weekly_num - 1
    index_file = Path(__file__).parent.parent.parent / 'trees' / 'weekly' / 'index.md'
    
    if not index_file.exists():
        return
    
    # è¯»å–index.md
    with open(index_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å°†ä¸Šä¸€å‘¨çš„[+]æ”¹ä¸º[+-]
    old_embed = f'[+](/weekly/weekly{previous_num}.md#:embed)'
    new_embed = f'[+-](/weekly/weekly{previous_num}.md#:embed)'
    
    if old_embed in content:
        content = content.replace(old_embed, new_embed)
        
        # ä¿å­˜æ›´æ–°åçš„å†…å®¹
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ“ å·²æ›´æ–° weekly{previous_num} çš„embedæ ¼å¼ï¼š[+] â†’ [+-]")

def parse_reviewed_md(md_file):
    """è§£æå·²reviewçš„MDæ–‡ä»¶ï¼Œæå–Packageå’ŒProjectçš„URL"""
    with open(md_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–PackageåŒºçš„æ‰€æœ‰URLï¼ˆåŒ¹é…åˆ°ä¸‹ä¸€ä¸ªemoji sectionï¼Œå¦‚ ## ğŸš€ æˆ– ## âš ï¸ï¼‰
    pkg_section = re.search(r'## ğŸ“¦ Package.*?\n(.*?)(?=\n## [ğŸš€âš ï¸]|\Z)', content, re.DOTALL)
    packages = re.findall(r'https://github\.com/[^/\s]+/[^\s\)]+', pkg_section.group(1)) if pkg_section else []
    
    # æå–ProjectåŒºçš„æ‰€æœ‰URL
    proj_section = re.search(r'## ğŸš€ Project.*?\n(.*?)(?=\n## âš ï¸|\Z)', content, re.DOTALL)
    projects = re.findall(r'https://github\.com/[^/\s]+/[^\s\)]+', proj_section.group(1)) if proj_section else []
    
    return packages, projects

def load_full_data(md_file):
    """åŠ è½½å®Œæ•´æ•°æ®JSON"""
    json_file = md_file.replace('.md', '_full_data.json')
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(json_file).exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {json_file}")
        print(f"è¯·ç¡®ä¿å…ˆè¿è¡Œ bot.py ç”Ÿæˆå®Œæ•´æ•°æ®")
        sys.exit(1)
    
    # å°è¯•åŠ è½½JSON
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")
        print(f"æ–‡ä»¶å¯èƒ½å·²æŸå: {json_file}")
        sys.exit(1)

def detect_weekly_number():
    """è‡ªåŠ¨æ£€æµ‹weeklyç¼–å·"""
    # ä»è„šæœ¬ä½ç½®æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    weekly_dir = project_root / 'trees' / 'weekly'
    
    if not weekly_dir.exists():
        return 1
    
    # åªåŒ¹é…ç›®å½•ï¼Œä¸åŒ…æ‹¬.mdæ–‡ä»¶
    weekly_dirs = [d for d in weekly_dir.iterdir() if d.is_dir() and d.name.startswith('weekly')]
    if not weekly_dirs:
        return 1
    
    numbers = []
    for d in weekly_dirs:
        match = re.search(r'weekly(\d+)', d.name)
        if match:
            numbers.append(int(match.group(1)))
    
    return max(numbers) + 1 if numbers else 1

def format_readme(readme, max_chars=1000):
    """æ ¼å¼åŒ–READMEï¼šæ¦‚è¿°+åŠŸèƒ½åˆ—è¡¨+ç”¨æ³•ç¤ºä¾‹"""
    if not readme:
        return "*æ— README*"
    
    # æˆªå–å‰1000å­—
    snippet = readme[:max_chars]
    
    # å°è¯•æå–ç»“æ„åŒ–ä¿¡æ¯
    lines = snippet.split('\n')
    
    # æ¦‚è¿°ï¼ˆå‰5è¡Œï¼‰
    overview = '\n'.join(lines[:5])
    
    # åŠŸèƒ½åˆ—è¡¨ï¼ˆæŸ¥æ‰¾- å¼€å¤´çš„è¡Œï¼‰
    features = [line for line in lines if line.strip().startswith('-')]
    
    if features:
        return f"**æ¦‚è¿°**:\n{overview}\n\n**ä¸»è¦åŠŸèƒ½**:\n" + '\n'.join(features[:5])
    else:
        return overview

def format_code_files(code_files):
    """æ ¼å¼åŒ–ä»£ç æ–‡ä»¶ï¼šè·¯å¾„åˆ—è¡¨ + å…³é”®ä»£ç """
    if not code_files:
        return "*æ— ä»£ç æ–‡ä»¶*"
    
    # è·¯å¾„åˆ—è¡¨
    paths = [f"- `{cf['path']}`" for cf in code_files[:10]]  # æœ€å¤š10ä¸ª
    
    # å…³é”®ä»£ç ï¼ˆmain.mbtæˆ–ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼‰
    main_file = next((cf for cf in code_files if 'main.mbt' in cf['path']), code_files[0])
    
    return f"**æ–‡ä»¶åˆ—è¡¨**:\n" + '\n'.join(paths) + f"\n\n**å…³é”®ä»£ç ** (`{main_file['path']}`):\n```moonbit\n{main_file['content'][:500]}...\n```"

def extract_real_examples(weekly_num):
    """ä»ä¸Šä¸€æœŸå‘¨æŠ¥æå–çœŸå®ç¤ºä¾‹"""
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    last_weekly_dir = project_root / 'trees' / 'weekly' / f'weekly{weekly_num-1}'
    
    examples = {
        'package': None,
        'project': None
    }
    
    # æå–Packageç¤ºä¾‹
    pkg_file = last_weekly_dir / 'packages.md'
    if pkg_file.exists():
        try:
            content = pkg_file.read_text(encoding='utf-8')
            # æå–BEGINå’ŒENDä¹‹é—´çš„ç¬¬ä¸€ä¸ªæ¡ç›®ï¼ˆå»æ‰frontmatterï¼‰
            match = re.search(r'<!-- BEGIN: packages -->(.*?)<!-- END: packages -->', content, re.DOTALL)
            if match:
                entries_text = match.group(1).strip()
                # å–ç¬¬ä¸€ä¸ªæ¡ç›®ï¼ˆé€šå¸¸ä»¥ä½œè€…å¼€å¤´ï¼Œåˆ°ç¬¬ä¸€ä¸ªç©ºè¡Œç»“æŸï¼‰
                lines = [l for l in entries_text.split('\n') if l.strip()]
                if lines:
                    # å–å‰3è¡Œä½œä¸ºç¤ºä¾‹
                    examples['package'] = '\n'.join(lines[:3])
        except:
            pass
    
    # æå–Projectç¤ºä¾‹
    proj_file = last_weekly_dir / 'projects.md'
    if proj_file.exists():
        try:
            content = proj_file.read_text(encoding='utf-8')
            match = re.search(r'<!-- BEGIN: projects -->(.*?)<!-- END: projects -->', content, re.DOTALL)
            if match:
                entries_text = match.group(1).strip()
                lines = [l for l in entries_text.split('\n') if l.strip()]
                if lines:
                    examples['project'] = '\n'.join(lines[:3])
        except:
            pass
    
    return examples

def generate_writing_guide(md_file):
    """ç”Ÿæˆå†™ä½œæŒ‡å¼•æ–‡æ¡£"""
    
    # è§£æreviewåçš„åˆ†ç±»
    pkg_urls, proj_urls = parse_reviewed_md(md_file)
    # æ ¡éªŒæ˜¯å¦å·²å®Œæˆreviewï¼ˆå­˜åœ¨ç­¾åï¼‰
    with open(md_file, 'r', encoding='utf-8') as f:
        whole = f.read()
    reviewed = (REVIEW_SIGNATURE_KEY in whole)
    
    # åŠ è½½å®Œæ•´æ•°æ®
    full_data = load_full_data(md_file)
    
    # æ£€æµ‹weeklyç¼–å·
    weekly_num = detect_weekly_number()
    
    # æå–æ—¥æœŸ - ä»MDæ–‡ä»¶æ ‡é¢˜æå–æœç´¢æ—¥æœŸ
    with open(md_file, 'r', encoding='utf-8') as f:
        first_line = f.readline()
        date_match = re.search(r'(\d{4}-\d{2}-\d{2})', first_line)
    
    search_date = date_match.group(1) if date_match else datetime.now().strftime('%Y-%m-%d')
    
    # è®¡ç®—å‘¨æ•°æè¿°ï¼ˆå‡è®¾æœç´¢æ—¥æœŸæ˜¯å¼€å§‹æ—¥æœŸï¼Œç»“æŸæ—¥æœŸæ˜¯å¼€å§‹æ—¥æœŸ+7å¤©ï¼‰
    start_date = search_date
    end_date = (datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=6)).strftime('%Y-%m-%d')
    week_description = calculate_week_description(start_date, end_date)
    
    # æå–çœŸå®ç¤ºä¾‹
    real_examples = extract_real_examples(weekly_num)
    
    # ç”ŸæˆæŒ‡ä»¤æ–‡æ¡£
    instructions_doc = f"""# Weekly {weekly_num} å‘¨æŠ¥æ¡ç›®å†™ä½œæŒ‡å¼•

> ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}  
> ğŸ“¦ Package: {len(pkg_urls)}ä¸ª | ğŸš€ Project: {len(proj_urls)}ä¸ª

---

## ğŸš¨ æ ¸å¿ƒè§„åˆ™ï¼ˆè¿åå°†å¯¼è‡´é‡åšï¼‰

### âœ… å¿…é¡»åšåˆ°ï¼š
1. **ä»…å¤„ç†æ•°æ®æ–‡æ¡£ä¸­çš„ä»“åº“**ï¼ˆ{len(pkg_urls) + len(proj_urls)}ä¸ªï¼‰ï¼Œä¸å¾—å¢åˆ 
2. **æ–‡ä»¶è·¯å¾„**ï¼ˆå’Œweekly{weekly_num-1}åŒçº§ï¼‰ï¼š
   - `trees/weekly/weekly{weekly_num}.md` â† ä¸»æ–‡æ¡£
   - `trees/weekly/weekly{weekly_num}/packages.md` â† Packageæ¡ç›®
   - `trees/weekly/weekly{weekly_num}/projects.md` â† Projectæ¡ç›®
   - `trees/weekly/weekly{weekly_num}/official.md` â† ç©ºæ¨¡æ¿ï¼ˆåªä¿ç•™frontmatterï¼Œä¸è¦æ·»åŠ ä»»ä½•é”šç‚¹æ ‡è®°ï¼‰
   - `trees/weekly/weekly{weekly_num}/community.md` â† ç©ºæ¨¡æ¿ï¼ˆåªä¿ç•™frontmatterï¼Œä¸è¦æ·»åŠ ä»»ä½•é”šç‚¹æ ‡è®°ï¼‰

3. **æ ¼å¼è¦æ±‚**ï¼š
   - æ¯æ¡2-3å¥ï¼ˆç”¨é€”+åŠŸèƒ½+ç‰¹æ€§ï¼‰
   - æ¡ç›®é—´æ— ç©ºè¡Œ
   - ç›´æ¥ç¼–è¾‘æ–‡ä»¶å†…å®¹ï¼Œæ·»åŠ Package/Projectæ¡ç›®
   - ä¿æŒMarkdownæ ¼å¼ï¼Œä¸è¦æ·»åŠ ä»»ä½•ç‰¹æ®Šæ ‡è®°
   - æ–‡ä»¶æœ«å°¾æ°å¥½1ä¸ªæ¢è¡Œ

### âŒ ä¸¥ç¦ï¼š
- é‡å¤frontmatterï¼ˆæ¯ä¸ªæ–‡ä»¶åªèƒ½æœ‰ä¸€ä¸ª`---`å—ï¼‰
- æ–‡ä»¶å°¾éƒ¨å†æ¬¡ç²˜è´´æ•´æ®µæ¨¡æ¿
- æ·»åŠ ä»»ä½•ç‰¹æ®Šæ ‡è®°æˆ–é”šç‚¹
- è‡†æµ‹ä¿¡æ¯ï¼ˆå¿…é¡»åŸºäºREADMEå’Œæä¾›çš„æ•°æ®ï¼‰

---

## ğŸ“– é£æ ¼å‚ç…§

**è¯·å…ˆé˜…è¯»ä»¥ä¸‹æ–‡ä»¶äº†è§£å†™ä½œé£æ ¼**ï¼š
- `trees/weekly/weekly{weekly_num-1}/packages.md` - é˜…è¯»å‰2æ¡Packageæ¡ç›®
- `trees/weekly/weekly{weekly_num-1}/projects.md` - é˜…è¯»å‰2æ¡Projectæ¡ç›®

**è‹¥æ— æ³•è®¿é—®å†å²æ–‡ä»¶ï¼Œè¯·æŒ‰ä»¥ä¸‹æœ€å°è§„èŒƒ**ï¼š
- ä½œè€…ï¼š`[username æ˜µç§°](url)` æˆ– `[username](url)`ï¼ˆæ— æ˜µç§°æ—¶ï¼‰
- ç±»å‹ï¼šåº“/æ¡†æ¶/ç»‘å®š/å·¥å…·é›†ï¼ˆPackageï¼‰| åº”ç”¨/æ¸¸æˆ/CLI/ç¤ºä¾‹ï¼ˆProjectï¼‰
- ç”¨é€”ï¼šä¸€å¥è¯è¯´æ¸…æ¥šå¹²ä»€ä¹ˆç”¨çš„
- åŠŸèƒ½ï¼šä»READMEæç‚¼3-5ä¸ªæ ¸å¿ƒåŠŸèƒ½
- ç‰¹æ€§ï¼šæŠ€æœ¯äº®ç‚¹æˆ–åº”ç”¨åœºæ™¯

---

## ğŸ“‹ æ‰§è¡Œæ­¥éª¤

### Step 1: è®¿é—®ä»“åº“URL
è®¿é—®æ•°æ®æ–‡æ¡£ä¸­æ¯ä¸ªä»“åº“çš„GitHubé¡µé¢ï¼Œäº†è§£é¡¹ç›®æ•´ä½“æƒ…å†µ

### Step 2: ç»“åˆæ•°æ®ç¼–å†™
- ä½¿ç”¨æ•°æ®æ–‡æ¡£ä¸­çš„æŠ€æœ¯ä¿¡æ¯è¡¥å……ç†è§£
- å‚ç…§å†å²é£æ ¼ç¼–å†™æ¡ç›®
- ç›´æ¥ç¼–è¾‘æ–‡ä»¶å†…å®¹ï¼Œæ·»åŠ æ¡ç›®

### Step 3: åˆ›å»ºæ–‡ä»¶ç»“æ„
- åˆ›å»º `trees/weekly/weekly{weekly_num}/` ç›®å½•
- åˆ›å»º4ä¸ªå­æ–‡æ¡£ï¼špackages.mdã€projects.mdã€official.mdã€community.md
- åˆ›å»ºä¸»æ–‡æ¡£ï¼š`trees/weekly/weekly{weekly_num}.md`
- æ›´æ–°ç´¢å¼•ï¼šåœ¨ `trees/weekly/index.md` æœ«å°¾æ·»åŠ embedè¡Œï¼ˆä½¿ç”¨ `[+]` æ ¼å¼ï¼‰

### ä¸»æ–‡æ¡£æ¨¡æ¿ï¼š
```markdown
---
title: Weekly{weekly_num} ç¤¾åŒºå‘¨æŠ¥ {start_date} ~ {end_date}
---

è¿™é‡Œæ˜¯ {start_date} ~ {end_date} çš„ç¤¾åŒºå‘¨æŠ¥ï¼Œ{week_description}ã€‚

[+](/weekly/weekly{weekly_num}/official.md#:embed)

[+](/weekly/weekly{weekly_num}/projects.md#:embed)

[+](/weekly/weekly{weekly_num}/packages.md#:embed)

[+](/weekly/weekly{weekly_num}/community.md#:embed)
```

---

## ğŸ“‹ æ ¼å¼è¦æ±‚è¯¦è§£

### âœ… æ­£ç¡®çš„embedæ ¼å¼ï¼š
```
[+](/weekly/weekly{weekly_num}/official.md#:embed)
[+](/weekly/weekly{weekly_num}/projects.md#:embed)
[+](/weekly/weekly{weekly_num}/packages.md#:embed)
[+](/weekly/weekly{weekly_num}/community.md#:embed)
```

### âŒ é”™è¯¯çš„embedæ ¼å¼ï¼ˆç¦æ­¢ä½¿ç”¨ï¼‰ï¼š
```
[+-](/weekly/weekly{weekly_num}/official.md#:embed)  â† é”™è¯¯ï¼šå†å²å‘¨æŠ¥æ ¼å¼
[+](/weekly/weekly{weekly_num}/official.md#:embed)   â† é”™è¯¯ï¼šå¤šä½™ç©ºæ ¼
```

### âœ… æ­£ç¡®çš„å­æ–‡æ¡£æ ‡é¢˜ï¼š
- `title: æœ¬å‘¨å®˜æ–¹é‡è¦åŠ¨æ€`
- `title: æœ¬å‘¨ç¤¾åŒºåŠ¨æ€`
- `title: æœ¬å‘¨ç¤¾åŒºæ–°å¢ä¼˜è´¨é¡¹ç›®`
- `title: æœ¬å‘¨ç¤¾åŒºæ–°å¢ä¼˜è´¨åŒ…`

### âŒ é”™è¯¯çš„å­æ–‡æ¡£æ ‡é¢˜ï¼ˆç¦æ­¢ä½¿ç”¨ï¼‰ï¼š
- `title: å®˜æ–¹åŠ¨æ€`  â† é”™è¯¯ï¼šç¼ºå°‘"æœ¬å‘¨"å’Œ"é‡è¦"
- `title: ç¤¾åŒºåŠ¨æ€`  â† é”™è¯¯ï¼šç¼ºå°‘"æœ¬å‘¨"

### âœ… ç©ºæ–‡æ¡£çš„æ­£ç¡®æ ¼å¼ï¼ˆofficial.mdå’Œcommunity.mdï¼‰ï¼š
```markdown
---
title: æœ¬å‘¨å®˜æ–¹é‡è¦åŠ¨æ€
---

```

### âŒ ç©ºæ–‡æ¡£çš„é”™è¯¯æ ¼å¼ï¼ˆç¦æ­¢ä½¿ç”¨ï¼‰ï¼š
```markdown
---
title: æœ¬å‘¨å®˜æ–¹é‡è¦åŠ¨æ€
---

<!-- ä»»ä½•ç‰¹æ®Šæ ‡è®° -->
```
**æ³¨æ„**ï¼šç©ºæ–‡æ¡£åªä¿ç•™frontmatterï¼Œä¸è¦æ·»åŠ ä»»ä½•ç‰¹æ®Šæ ‡è®°ï¼

## âœ… éªŒè¯æ¸…å•

ç”Ÿæˆå®Œæˆåæ£€æŸ¥ï¼š
- [ ] æ–‡ä»¶æ•°é‡æ­£ç¡®ï¼ˆ5ä¸ªæ–‡ä»¶ï¼‰
- [ ] æ¡ç›®æ•°é‡ï¼šPackage {len(pkg_urls)}ä¸ªï¼ŒProject {len(proj_urls)}ä¸ª
- [ ] æ¯æ¡åŒ…å«ï¼šä½œè€…+ç”¨é€”+åŠŸèƒ½
- [ ] æ— é‡å¤frontmatter
- [ ] æ— æ–‡ä»¶å°¾éƒ¨æ¨¡æ¿ç²˜è´´
- [ ] index.mdå·²æ›´æ–°
- [ ] embedæ ¼å¼ä½¿ç”¨ `[+]`ï¼ˆä¸æ˜¯ `[+-]`ï¼‰
- [ ] å­æ–‡æ¡£æ ‡é¢˜åŒ…å«"æœ¬å‘¨"å­—æ ·
- [ ] æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œæ— ç‰¹æ®Šæ ‡è®°

**ç°åœ¨å¼€å§‹æ‰§è¡Œï¼**
"""
    
    # ç”Ÿæˆæ•°æ®æ–‡æ¡£
    data_doc = {
        'weekly_num': weekly_num,
        'start_date': start_date,
        'end_date': end_date,
        'week_description': week_description,
        'packages': [],
        'projects': []
    }
    
    # å¤„ç†Packageæ•°æ®
    missing_count = 0
    for i, url in enumerate(pkg_urls, 1):
        if url not in full_data:
            print(f"âš ï¸  è­¦å‘Šï¼šPackage URL {url} åœ¨æ•°æ®ä¸­æ‰¾ä¸åˆ°ï¼Œè·³è¿‡")
            missing_count += 1
            continue
        
        repo = full_data[url]['repo']
        data = full_data[url]['full']
        
        author_info = repo.get('author_info', {})
        readme = data.get('readme', '')
        readme_brief = readme[:300] + '...' if len(readme) > 300 else readme
        
        # æå–å…³é”®ä»£ç ç‰‡æ®µ
        code_files = data.get('code_files', [])
        key_code = ''
        if code_files:
            main_file = next((cf for cf in code_files if 'main.mbt' in cf.get('path', '')), code_files[0])
            key_code = main_file.get('content', '')[:300] + '...' if len(main_file.get('content', '')) > 300 else main_file.get('content', '')
        
        # æŠ€æœ¯ä¿¡å·
        tech_signals = []
        if data.get('has_lib'):
            tech_signals.append('libç›®å½•')
        if any('main.mbt' in cf.get('path', '') for cf in code_files):
            tech_signals.append('main.mbt')
        if data.get('moon_mod'):
            tech_signals.append('moon.mod.json')
        
        package_data = {
            'index': i,
            'name': repo['name'],
            'url': url,
            'category': 'Package',
            'author': {
                'username': author_info.get('username', ''),
                'nickname': author_info.get('nickname', ''),
                'profile_url': f"https://github.com/{author_info.get('username', '')}" if author_info.get('username') else '',
                'display': author_info.get('display', '')
            },
            'description': repo.get('description', ''),
            'readme_summary': readme_brief,
            'key_code': key_code,
            'tech_signals': tech_signals,
            'metadata': {
                'stars': repo.get('stars', 0),
                'created_at': repo.get('created_at', ''),
                'topics': repo.get('topics', [])
            }
        }
        data_doc['packages'].append(package_data)
    
    # å¤„ç†Projectæ•°æ®
    for i, url in enumerate(proj_urls, 1):
        if url not in full_data:
            print(f"âš ï¸  è­¦å‘Šï¼šProject URL {url} åœ¨æ•°æ®ä¸­æ‰¾ä¸åˆ°ï¼Œè·³è¿‡")
            missing_count += 1
            continue
        
        repo = full_data[url]['repo']
        data = full_data[url]['full']
        
        author_info = repo.get('author_info', {})
        readme = data.get('readme', '')
        readme_brief = readme[:300] + '...' if len(readme) > 300 else readme
        
        # æå–å…³é”®ä»£ç ç‰‡æ®µ
        code_files = data.get('code_files', [])
        key_code = ''
        if code_files:
            main_file = next((cf for cf in code_files if 'main.mbt' in cf.get('path', '')), code_files[0])
            key_code = main_file.get('content', '')[:300] + '...' if len(main_file.get('content', '')) > 300 else main_file.get('content', '')
        
        # æŠ€æœ¯ä¿¡å·
        tech_signals = []
        if any('cmd/main' in cf.get('path', '') for cf in code_files):
            tech_signals.append('cmd/main')
        if any('main.mbt' in cf.get('path', '') for cf in code_files):
            tech_signals.append('main.mbt')
        if data.get('moon_mod'):
            tech_signals.append('moon.mod.json')
        
        project_data = {
            'index': i,
            'name': repo['name'],
            'url': url,
            'category': 'Project',
            'author': {
                'username': author_info.get('username', ''),
                'nickname': author_info.get('nickname', ''),
                'profile_url': f"https://github.com/{author_info.get('username', '')}" if author_info.get('username') else '',
                'display': author_info.get('display', '')
            },
            'description': repo.get('description', ''),
            'readme_summary': readme_brief,
            'key_code': key_code,
            'tech_signals': tech_signals,
            'metadata': {
                'stars': repo.get('stars', 0),
                'created_at': repo.get('created_at', ''),
                'topics': repo.get('topics', [])
            }
        }
        data_doc['projects'].append(project_data)
    
    # è‡ªåŠ¨æ›´æ–°ä¸Šä¸€å‘¨çš„embedæ ¼å¼ï¼ˆä»[+]æ”¹ä¸º[+-]ï¼‰
    update_previous_weekly_embed(weekly_num)
    
    # ä¿å­˜æŒ‡ä»¤æ–‡æ¡£
    instructions_file = md_file.replace('repos_', 'writing_guide_instructions_')
    with open(instructions_file, 'w', encoding='utf-8') as f:
        f.write(instructions_doc)
    
    # ä¿å­˜æ•°æ®æ–‡æ¡£
    data_file = md_file.replace('repos_', 'writing_guide_data_').replace('.md', '.json')
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump(data_doc, f, ensure_ascii=False, indent=2)
    
    return instructions_file, data_file, weekly_num

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python generate_writing_guide.py output/repos_weekly15_2025-10-14.md")
        sys.exit(1)
    
    md_file = sys.argv[1]
    instructions_file, data_file, weekly_num = generate_writing_guide(md_file)
    
    print(f"""
{'=' * 60}
å†™ä½œæŒ‡å¼•å·²ç”Ÿæˆ
{'=' * 60}

æŒ‡ä»¤æ–‡æ¡£: {instructions_file}
æ•°æ®æ–‡æ¡£: {data_file}
Weekly {weekly_num}

ä¸‹ä¸€æ­¥:
åœ¨Cursoré‡ŒåŒæ—¶å‘é€:

@{instructions_file}
@{data_file}

æŒ‰ç…§æŒ‡ä»¤è¦æ±‚ç”Ÿæˆå‘¨æŠ¥æ¡ç›®

{'=' * 60}
""")
